{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import loader; \n",
    "import sklearn_classifiers\n",
    "import keras_classifiers\n",
    "import utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import importlib;\n",
    "importlib.reload(loader); \n",
    "importlib.reload(sklearn_classifiers);\n",
    "importlib.reload(utils);\n",
    "importlib.reload(keras_classifiers);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import dhash\n",
    "\n",
    "hash_size = 8\n",
    "\n",
    "X_test_dhash = utils.Images_to_DHash(x_test, size = hash_size)\n",
    "X_train_dhash = utils.Images_to_DHash(x_train, size = hash_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest on DHash data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 128)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Julio/GitHub/SandBox/Python/CNN/CNN_and_Dhast_MNIST/sklearn_classifiers.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit (trainX, trainY)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.27      0.29      0.28      1000\n",
      "          1       0.33      0.43      0.37      1000\n",
      "          2       0.22      0.23      0.23      1000\n",
      "          3       0.20      0.18      0.19      1000\n",
      "          4       0.21      0.17      0.18      1000\n",
      "          5       0.24      0.22      0.23      1000\n",
      "          6       0.30      0.28      0.29      1000\n",
      "          7       0.34      0.34      0.34      1000\n",
      "          8       0.34      0.30      0.32      1000\n",
      "          9       0.30      0.32      0.31      1000\n",
      "\n",
      "avg / total       0.27      0.28      0.27     10000\n",
      "\n",
      "CPU times: user 14.3 s, sys: 800 ms, total: 15.1 s\n",
      "Wall time: 2.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train RandomForest and test its performance\n",
    "tree = sklearn_classifiers.fit_RandomForest(X_train_dhash, y_train, X_test_dhash, y_test, n_estimators = hash_size**2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random Forest on Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# load data\n",
    "(x_train, y_train, x_test, y_test) = loader.get_data(normalize = 0, squeeze = 1)\n",
    "\n",
    "# transform 3D data into 2D data. (rows = cases, columns = voxels)\n",
    "Xtrain, Xtest = utils.images_to_matrix(x_train, x_test)\n",
    "\n",
    "# train RandomForest and test its performance\n",
    "tree_model = sklearn_classifiers.fit_ExtraTrees(Xtrain, y_train, Xtest, y_test, n_estimators = 64);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model.feature_importances_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "x = tree_model.feature_importances_;\n",
    "plt.barh(np.arange(784), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X.  Randomized decision treeson DHash data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# load data\n",
    "(x_train, y_train, x_test, y_test) = loader.get_data(normalize = 0, squeeze = 1)\n",
    "\n",
    "# transform each image into a binary Dhash (columns and rows)\n",
    "hash_size = 8\n",
    "X_train_dhash = utils.Images_to_DHash(x_train * 2, size = hash_size); # normalization is not beneficial\n",
    "X_test_dhash = utils.Images_to_DHash(x_test * 2, size = hash_size);   # normalization is not beneficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train RandomForest and test its performance\n",
    "importlib.reload(sklearn_classifiers);\n",
    "tree = sklearn_classifiers.fit_ExtraTrees(X_train_dhash, y_train, X_test_dhash, y_test,\n",
    "                                                                           n_estimators = 64);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.n_features_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# load data\n",
    "(x_train, y_train, x_test, y_test) = loader.get_data(normalize = 0, squeeze = 1)\n",
    "\n",
    "# transform each image into a binary Dhash (columns and rows)\n",
    "X_train_dhash = utils.Images_to_DHash(x_train * 2, size = hash_size); # normalization is not beneficial\n",
    "X_test_dhash = utils.Images_to_DHash(x_test * 2, size = hash_size);   # normalization is not beneficial\n",
    "\n",
    "# train RandomForest and test its performance\n",
    "tree = sklearn_classifiers.fit_RandomForest(X_train_dhash, y_train, X_test_dhash, y_test, n_estimators = hash_size**2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural Net on DHash data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "importlib.reload(keras_classifiers);\n",
    "model = keras_classifiers.fit_two_layer_NN(X_train_dhash, X_test_dhash, y_train, y_test, \n",
    "                                           num_epochs = 200, verbose_out = 1);\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural Net on Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train, x_test, y_test) = loader.get_data(normalize = 1, squeeze = 1)\n",
    "# transform 3D data into 2D data. (rows = cases, columns = voxels)\n",
    "Xtrain, Xtest = utils.images_to_matrix(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = keras_classifiers.fit_two_layer_NN(Xtrain, Xtest, y_train, y_test, \n",
    "                                           num_epochs = 200, verbose_out = 0);\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
