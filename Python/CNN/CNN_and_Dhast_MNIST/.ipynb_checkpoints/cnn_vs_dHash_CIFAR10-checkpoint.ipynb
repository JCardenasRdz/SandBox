{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import loader; \n",
    "import sklearn_classifiers\n",
    "import keras_classifiers\n",
    "import utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import importlib;\n",
    "importlib.reload(loader); \n",
    "importlib.reload(sklearn_classifiers);\n",
    "importlib.reload(utils);\n",
    "importlib.reload(keras_classifiers);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import dhash\n",
    "\n",
    "Dhash_xtest = utils.Images_to_DHash(x_test)\n",
    "Dhash_xtrain = utils.Images_to_DHash(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest on DHash data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# train RandomForest and test its performance\n",
    "tree = sklearn_classifiers.fit_RandomForest(X_train_dhash, y_train, X_test_dhash, y_test, n_estimators = hash_size**2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random Forest on Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# load data\n",
    "(x_train, y_train, x_test, y_test) = loader.get_data(normalize = 0, squeeze = 1)\n",
    "\n",
    "# transform 3D data into 2D data. (rows = cases, columns = voxels)\n",
    "Xtrain, Xtest = utils.images_to_matrix(x_train, x_test)\n",
    "\n",
    "# train RandomForest and test its performance\n",
    "tree_model = sklearn_classifiers.fit_ExtraTrees(Xtrain, y_train, Xtest, y_test, n_estimators = 64);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model.feature_importances_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "x = tree_model.feature_importances_;\n",
    "plt.barh(np.arange(784), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X.  Randomized decision treeson DHash data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# load data\n",
    "(x_train, y_train, x_test, y_test) = loader.get_data(normalize = 0, squeeze = 1)\n",
    "\n",
    "# transform each image into a binary Dhash (columns and rows)\n",
    "hash_size = 8\n",
    "X_train_dhash = utils.Images_to_DHash(x_train * 2, size = hash_size); # normalization is not beneficial\n",
    "X_test_dhash = utils.Images_to_DHash(x_test * 2, size = hash_size);   # normalization is not beneficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train RandomForest and test its performance\n",
    "importlib.reload(sklearn_classifiers);\n",
    "tree = sklearn_classifiers.fit_ExtraTrees(X_train_dhash, y_train, X_test_dhash, y_test,\n",
    "                                                                           n_estimators = 64);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.n_features_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# load data\n",
    "(x_train, y_train, x_test, y_test) = loader.get_data(normalize = 0, squeeze = 1)\n",
    "\n",
    "# transform each image into a binary Dhash (columns and rows)\n",
    "X_train_dhash = utils.Images_to_DHash(x_train * 2, size = hash_size); # normalization is not beneficial\n",
    "X_test_dhash = utils.Images_to_DHash(x_test * 2, size = hash_size);   # normalization is not beneficial\n",
    "\n",
    "# train RandomForest and test its performance\n",
    "tree = sklearn_classifiers.fit_RandomForest(X_train_dhash, y_train, X_test_dhash, y_test, n_estimators = hash_size**2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural Net on DHash data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "importlib.reload(keras_classifiers);\n",
    "model = keras_classifiers.fit_two_layer_NN(X_train_dhash, X_test_dhash, y_train, y_test, \n",
    "                                           num_epochs = 200, verbose_out = 1);\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural Net on Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train, x_test, y_test) = loader.get_data(normalize = 1, squeeze = 1)\n",
    "# transform 3D data into 2D data. (rows = cases, columns = voxels)\n",
    "Xtrain, Xtest = utils.images_to_matrix(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = keras_classifiers.fit_two_layer_NN(Xtrain, Xtest, y_train, y_test, \n",
    "                                           num_epochs = 200, verbose_out = 0);\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
